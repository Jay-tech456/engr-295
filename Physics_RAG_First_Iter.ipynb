{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce10ef0b-ad60-483f-b6d5-9e05373dc0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.19-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.35 (from langchain)\n",
      "  Downloading langchain_core-0.3.40-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.11-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.38-cp39-cp39-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.11.13-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting numpy<2,>=1.26.4 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.3.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.18.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (69 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.35->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.9/site-packages (from langchain-core<1.0.0,>=0.3.35->langchain) (4.12.2)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.15-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached zstandard-0.23.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.27.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.4.1-cp39-cp39-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.2.2)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langchain-0.3.19-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.13-cp39-cp39-macosx_11_0_arm64.whl (456 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.3.40-py3-none-any.whl (414 kB)\n",
      "Using cached langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Downloading langsmith-0.3.11-py3-none-any.whl (335 kB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Downloading PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl (172 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading SQLAlchemy-2.0.38-cp39-cp39-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp39-cp39-macosx_10_9_universal2.whl (197 kB)\n",
      "Downloading frozenlist-1.5.0-cp39-cp39-macosx_11_0_arm64.whl (52 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading multidict-6.1.0-cp39-cp39-macosx_11_0_arm64.whl (29 kB)\n",
      "Downloading orjson-3.10.15-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (250 kB)\n",
      "Downloading propcache-0.3.0-cp39-cp39-macosx_11_0_arm64.whl (45 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached yarl-1.18.3-cp39-cp39-macosx_11_0_arm64.whl (92 kB)\n",
      "Using cached zstandard-0.23.0-cp39-cp39-macosx_11_0_arm64.whl (633 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, urllib3, tenacity, SQLAlchemy, sniffio, PyYAML, pydantic-core, propcache, orjson, numpy, multidict, jsonpointer, idna, h11, frozenlist, charset-normalizer, certifi, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, requests, pydantic, jsonpatch, httpcore, anyio, aiosignal, requests-toolbelt, httpx, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.38 aiohappyeyeballs-2.4.6 aiohttp-3.11.13 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.8.0 async-timeout-4.0.3 attrs-25.1.0 certifi-2025.1.31 charset-normalizer-3.4.1 frozenlist-1.5.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.19 langchain-core-0.3.40 langchain-text-splitters-0.3.6 langsmith-0.3.11 multidict-6.1.0 numpy-1.26.4 orjson-3.10.15 propcache-0.3.0 pydantic-2.10.6 pydantic-core-2.27.2 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.0.0 urllib3-2.3.0 yarl-1.18.3 zstandard-0.23.0\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "# Directions on how to run this\n",
    "\n",
    "# 1) Install Conda\n",
    "# 2) Create a Conda Environment\n",
    "    # conda create -n physics_ai python=3.9 -y\n",
    "# 3) Activate Conda Environment \n",
    "    # conda activate physics_ai\n",
    "\n",
    "# Install Libraries: \n",
    "    # pip install langchain\n",
    "    # pip install python-dotenv\n",
    "    # pip install -qU \"langchain[mistralai]\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0362b07e-e16c-4887-a3cd-9f5d131537a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1801670246.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[21], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install -qU \"langchain[mistralai]\"\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Version #1: Testing out the Mistral Model without system template constraints\n",
    "# This will answer any question you enter. Will not filter out physics level questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ee88401c-e11e-46ff-9600-9b7d6d0d76ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "# loading the Mistral API key\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4379ca55-d9f0-4e7d-90d6-7cb7407e4c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining your model itself\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"mistral-large-latest\", model_provider=\"mistralai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "101a4a6f-68b1-4431-b945-da1c1955d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f7cdcfb8-8ed8-494b-b0fa-2213a6b70b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today? If you're up for it, I can tell a joke to start our conversation. Here it is:\n",
      "\n",
      "What do you call a fake noodle?\n",
      "\n",
      "An impasta!\n",
      "I am a text-based AI model developed by the Mistral AI team. I'm here to assist you, answer questions, provide explanations, or just chat on a wide range of topics. I don't have personal experiences, feelings, or a physical presence, but I'm designed to understand and generate human-like text based on the data I've been trained on (up until 2023). How can I help you today?\n",
      "Sir Isaac Newton (1642-1726/27) was an English mathematician, physicist, and astronomer who is widely recognized as one of the most influential scientists in history. Here's a brief history of his life and achievements:\n",
      "\n",
      "### Early Life\n",
      "- **Birth**: Isaac Newton was born on December 25, 1642 (January 4, 1643, by the modern calendar), in Woolsthorpe, Lincolnshire, England.\n",
      "- **Childhood**: His father, also named Isaac Newton, died before he was born. Newton was raised by his grandmother after his mother remarried when he was three years old.\n",
      "- **Education**: He attended The King's School in Grantham and later enrolled at Trinity College, Cambridge, in 1661.\n",
      "\n",
      "### Academic Career\n",
      "- **Cambridge University**: Newton received his Bachelor of Arts degree in 1665 and his Master of Arts degree in 1668. He was elected a Fellow of Trinity College in 1667.\n",
      "- **Plague Years**: In 1665-1666, the Great Plague forced the closure of Cambridge University, and Newton returned to his family estate in Woolsthorpe. During this period, he made significant advancements in mathematics (including the development of calculus), optics, and the laws of motion and universal gravitation.\n",
      "- **Lucasian Chair**: In 1669, Newton was appointed the Lucasian Professor of Mathematics at Cambridge, a position he held until 1701.\n",
      "\n",
      "### Scientific Contributions\n",
      "- **Optics**: Newton's work in optics included his experiments with prisms and the nature of light, which he published in his book \"Opticks\" (1704). He demonstrated that white light is composed of all the colors of the spectrum.\n",
      "- **Mechanics and Gravitation**: His most famous work, \"Philosophiæ Naturalis Principia Mathematica\" (1687), often referred to as the \"Principia,\" laid the foundation for classical mechanics. It introduced the laws of motion and universal gravitation.\n",
      "- **Calculus**: Newton, along with Gottfried Wilhelm Leibniz, is credited with the development of calculus, although there was a significant controversy over who invented it first.\n",
      "\n",
      "### Later Life\n",
      "- **Royal Society**: Newton was elected a Fellow of the Royal Society in 1672 and became its president in 1703, a position he held until his death.\n",
      "- **Mint Master**: In 1696, Newton was appointed Warden of the Royal Mint, and in 1700, he became Master of the Mint, a position he held until his death.\n",
      "- **Knighthood**: In 1705, Newton was knighted by Queen Anne.\n",
      "\n",
      "### Death\n",
      "- **Final Years**: Newton continued to be active in his scientific and administrative roles until his death.\n",
      "- **Passing**: He died in his sleep on March 20, 1726 (March 31, 1727, by the modern calendar) and was buried in Westminster Abbey.\n",
      "\n",
      "### Legacy\n",
      "- **Influence**: Newton's work had a profound impact on the development of science and mathematics. His contributions to physics, astronomy, and mathematics are foundational to modern scientific thought.\n",
      "- **Honors**: Newton is often ranked as one of the most influential figures in the history of science, and his name is associated with numerous scientific principles and discoveries.\n",
      "\n",
      "Newton's life and work continue to inspire and inform scientific inquiry to this day, making him a pivotal figure in the Scientific Revolution.\n",
      "End of application\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"Please enter a query\")\n",
    "\n",
    "    if user_input.lower() == \"exit\": \n",
    "        break\n",
    "    output = model.invoke(user_input)\n",
    "    print(output.content)\n",
    "\n",
    "print(\"End of application\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d60d1cd-4662-49f6-949c-18e1cb275625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbec9207-d236-412c-a1f3-a613ba58d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version #  II --> Using Langchain and prompts to answer specifically for phsycis related questions\n",
    "# This Demo Is tailored towards having the LLM only answer Phsyics related questions. \n",
    "\n",
    "# It utilizes Langchain systemMess and SystemMessagePromptTemplate to filter out any other subject and will answer questions pretaining \n",
    "# to only the Physics subject\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b429ee-746d-4a5f-af64-6a165e6c9012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# https://python.langchain.com/docs/how_to/structured_output/\n",
    "from dotenv import load_dotenv\n",
    "# loading the Mistral API key\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "515bbe7d-ab24-4988-9a3b-36dcd6f984ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an AI assistant that only answers questions related to physics.  \n",
    "\n",
    "### **Guidelines:**\n",
    "1. **Answer only physics-related questions.**  \n",
    "   - Topics include classical mechanics, electromagnetism, quantum mechanics, thermodynamics, relativity, and other core physics subjects.  \n",
    "\n",
    "2. **Reject non-physics questions.**  \n",
    "   - If a question is outside the scope of physics (e.g., history, literature, biology, general math), respond with:  \n",
    "     **\"I can only answer physics-related questions.\"**  \n",
    "\n",
    "3. **Do not attempt to redirect or reframe unrelated questions.**  \n",
    "   - Example: If asked \"Who wrote Hamlet?\", simply respond:  \n",
    "     **\"I can only answer physics-related questions.\"**  \n",
    "   - Do not attempt to connect unrelated topics to physics.  \n",
    "\n",
    "4. **If a question is unclear, ask for clarification only if it seems related to physics.**  \n",
    "   - Otherwise, treat it as unrelated and do not answer.  \n",
    "\n",
    "Stick strictly to physics and avoid answering anything outside this domain. Be concise and factual in your responses.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ef88654-37ab-4a23-8907-93744bd46045",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessagePromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e17ddb3d-af5a-4a61-936f-d86751f6a096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "# Initialize your model, in this case, it is mistral. \n",
    "llm = init_chat_model(\"mistral-large-latest\", model_provider=\"mistralai\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05677279-da5d-4bac-a14d-79b2d50f9d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = system_message.format()\n",
    "\n",
    "\n",
    "messages = [system_message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7317025e-9c17-4349-9c56-8664461fd898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can only answer physics-related questions.Sir Isaac Newton's three laws of motion are:\n",
      "\n",
      "1. **First Law (Law of Inertia):** An object at rest stays at rest, and an object in motion stays in motion, both with constant velocity, unless acted upon by a net external force.\n",
      "2. **Second Law (F=ma):** The force acting on an object is equal to its mass times its acceleration; F = ma.\n",
      "3. **Third Law:** For every action, there is an equal and opposite reaction. This means that any force exerted onto another object will cause an equal force to be exerted back onto the original object.End of Program\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_query = input(\"Please enter a physics-related question (or type 'exit' to quit): \")\n",
    "    \n",
    "    if user_query.lower() == \"exit\":\n",
    "        break\n",
    "    messages.append(HumanMessage(content=user_query))\n",
    "    \n",
    "    for chunk in llm.stream(messages):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "print(\"End of Program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339b9c77-0a48-4c22-838a-30a0ff743612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37731f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Iteration with the Pinecone Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.prompts import SystemMessagePromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbd97bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# https://python.langchain.com/docs/how_to/structured_output/\n",
    "from dotenv import load_dotenv\n",
    "# loading the Mistral API key\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184235c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an AI assistant that only answers questions related to physics.  \n",
    "\n",
    "### **Guidelines:**\n",
    "1. **Answer only physics-related questions.**  \n",
    "   - Topics include classical mechanics, electromagnetism, quantum mechanics, thermodynamics, relativity, and other core physics subjects.  \n",
    "\n",
    "2. **Reject non-physics questions.**  \n",
    "   - If a question is outside the scope of physics (e.g., history, literature, biology, general math), respond with:  \n",
    "     **\"I can only answer physics-related questions.\"**  \n",
    "\n",
    "3. **Do not attempt to redirect or reframe unrelated questions.**  \n",
    "   - Example: If asked \"Who wrote Hamlet?\", simply respond:  \n",
    "     **\"I can only answer physics-related questions.\"**  \n",
    "   - Do not attempt to connect unrelated topics to physics.  \n",
    "\n",
    "4. **If a question is unclear, ask for clarification only if it seems related to physics.**  \n",
    "   - Otherwise, treat it as unrelated and do not answer.  \n",
    "\n",
    "Stick strictly to physics and avoid answering anything outside this domain. Be concise and factual in your responses.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessagePromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6e7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "# Initialize your model, in this case, it is mistral. \n",
    "llm = init_chat_model(\"mistral-large-latest\", model_provider=\"mistralai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68be007",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = system_message.format()\n",
    "\n",
    "\n",
    "messages = [system_message]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c76279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_query = input(\"Please enter a physics-related question (or type 'exit' to quit): \")\n",
    "    \n",
    "    if user_query.lower() == \"exit\":\n",
    "        break\n",
    "    messages.append(HumanMessage(content=user_query))\n",
    "    \n",
    "    for chunk in llm.stream(messages):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "\n",
    "\n",
    "print(\"End of Program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7fd0b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone\n",
      "  Downloading pinecone-6.0.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in ./.venv/lib/python3.9/site-packages (from pinecone) (2025.1.31)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n",
      "  Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./.venv/lib/python3.9/site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in ./.venv/lib/python3.9/site-packages (from pinecone) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in ./.venv/lib/python3.9/site-packages (from pinecone) (2.3.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Downloading pinecone-6.0.1-py3-none-any.whl (421 kB)\n",
      "Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: pinecone-plugin-interface, pinecone\n",
      "Successfully installed pinecone-6.0.1 pinecone-plugin-interface-0.0.7\n"
     ]
    }
   ],
   "source": [
    "# Install the Dependency\n",
    "# !pip install pinecone\n",
    "# !pip install langchain_pinecone\n",
    "# !pip install -U langchain-community\n",
    "# !pip install -qU langchain-\n",
    "# !pip install -qU langchain-nomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656dcdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "\n",
    "# *************** Using Mistral AI Model *****************************\n",
    "# from langchain_mistralai import MistralAIEmbeddings\n",
    "# embedding_model = MistralAIEmbeddings(model=\"mistral-embed\")\n",
    "# embedding_model.embed_query(\"Hello, world!\")\n",
    "# ****************** Size 1064 embedding *****************************\n",
    "\n",
    "\n",
    "# ****************** Using NomicEmbeddings ******************************\n",
    "import getpass\n",
    "import os\n",
    "from langchain_nomic import NomicEmbeddings\n",
    "\n",
    "if not os.environ.get(\"NOMIC_API_KEY\"):\n",
    "  os.environ[\"NOMIC_API_KEY\"] = getpass.getpass(\"Enter API key for Nomic: \")\n",
    "\n",
    "embeddings = NomicEmbeddings(model=\"nomic-embed-text-v1.5\")\n",
    "\n",
    "# ***************** Size 768 Embedding *************************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7fc8b8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "# print(len(embeddings.embed_query(\"hello world\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f7252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the official Langchain document \n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "if not os.getenv(\"PINECONE_API_KEY\"):\n",
    "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
    "\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a74ad0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "# index = pc.Index(\"physics\")\n",
    "vector_store = PineconeVectorStore(index=\"physics\", embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2f802d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "# retriever = vector_store.as_retriever(\n",
    "#     search_type=\"similarity_score_threshold\",\n",
    "#     search_kwargs={\"k\": 2, \"score_threshold\": 0.6},  # Lower threshold\n",
    "# )\n",
    "\n",
    "# vector_store.similarity_search(\"How does quantum field theory explain black hole thermodynamics?\")\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"k\": 1, \"score_threshold\": 0.76},\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e41fbad9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow does quantum field theory explain black hole thermodynamics?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[0;32m~/Desktop/Master's Project B/.venv/lib/python3.9/site-packages/langchain_core/retrievers.py:259\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 259\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/Desktop/Master's Project B/.venv/lib/python3.9/site-packages/langchain_core/vectorstores/base.py:1076\u001b[0m, in \u001b[0;36mVectorStoreRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1073\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorstore\u001b[38;5;241m.\u001b[39msimilarity_search(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimilarity_score_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1075\u001b[0m     docs_and_similarities \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1076\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_relevance_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m            \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1079\u001b[0m     )\n\u001b[1;32m   1080\u001b[0m     docs \u001b[38;5;241m=\u001b[39m [doc \u001b[38;5;28;01mfor\u001b[39;00m doc, _ \u001b[38;5;129;01min\u001b[39;00m docs_and_similarities]\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/Master's Project B/.venv/lib/python3.9/site-packages/langchain_core/vectorstores/base.py:554\u001b[0m, in \u001b[0;36mVectorStore.similarity_search_with_relevance_scores\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return docs and relevance scores in the range [0, 1].\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03m0 is dissimilar, 1 is most similar.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;124;03m    List of Tuples of (doc, similarity_score).\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    552\u001b[0m score_threshold \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 554\u001b[0m docs_and_similarities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_similarity_search_with_relevance_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    558\u001b[0m     similarity \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m similarity \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, similarity \u001b[38;5;129;01min\u001b[39;00m docs_and_similarities\n\u001b[1;32m    560\u001b[0m ):\n\u001b[1;32m    561\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRelevance scores must be between\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m 0 and 1, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdocs_and_similarities\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    564\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    565\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Master's Project B/.venv/lib/python3.9/site-packages/langchain_core/vectorstores/base.py:503\u001b[0m, in \u001b[0;36mVectorStore._similarity_search_with_relevance_scores\u001b[0;34m(self, query, k, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Default similarity search with relevance scores. Modify if necessary\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03min subclass.\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03mReturn docs and relevance scores in the range [0, 1].\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;124;03m    List of Tuples of (doc, similarity_score)\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    502\u001b[0m relevance_score_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_relevance_score_fn()\n\u001b[0;32m--> 503\u001b[0m docs_and_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [(doc, relevance_score_fn(score)) \u001b[38;5;28;01mfor\u001b[39;00m doc, score \u001b[38;5;129;01min\u001b[39;00m docs_and_scores]\n",
      "File \u001b[0;32m~/Desktop/Master's Project B/.venv/lib/python3.9/site-packages/langchain_pinecone/vectorstores.py:322\u001b[0m, in \u001b[0;36mPineconeVectorStore.similarity_search_with_score\u001b[0;34m(self, query, k, filter, namespace)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msimilarity_search_with_score\u001b[39m(\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    306\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     namespace: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m    311\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return pinecone documents most similar to query, along with scores.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m        List of Documents most similar to the query and score for each\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_by_vector_with_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Master's Project B/.venv/lib/python3.9/site-packages/langchain_pinecone/vectorstores.py:339\u001b[0m, in \u001b[0;36mPineconeVectorStore.similarity_search_by_vector_with_score\u001b[0;34m(self, embedding, k, filter, namespace)\u001b[0m\n\u001b[1;32m    337\u001b[0m     namespace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_namespace\n\u001b[1;32m    338\u001b[0m docs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 339\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m(\n\u001b[1;32m    340\u001b[0m     vector\u001b[38;5;241m=\u001b[39membedding,\n\u001b[1;32m    341\u001b[0m     top_k\u001b[38;5;241m=\u001b[39mk,\n\u001b[1;32m    342\u001b[0m     include_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    343\u001b[0m     namespace\u001b[38;5;241m=\u001b[39mnamespace,\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mfilter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfilter\u001b[39m,\n\u001b[1;32m    345\u001b[0m )\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatches\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    347\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'query'"
     ]
    }
   ],
   "source": [
    "results = retriever.invoke(\"How does quantum field theory explain black hole thermodynamics?\")\n",
    "\n",
    "if results:\n",
    "    for doc in results:\n",
    "        print(f\"Score: {doc.metadata.get('score', 'N/A')}\\nContent: {doc.metadata.get('content', 'No text available')}\\n\")\n",
    "else:\n",
    "    print(\"No matching documents found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0e1bdebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vectorstore = PineconeVectorStore(index_name=\"physics\", embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ccba0b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "index_name = \"physics\" \n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "# print(existing_indexes)\n",
    "\n",
    "#  Creates the Index if it does not exist already\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4e27d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9c97bf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found document with no `text` key. Skipping.\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(query=\"Blackholes\",k=1)\n",
    "for doc in results:\n",
    "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5b5d050a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n"
     ]
    }
   ],
   "source": [
    "query = \"How do magnetic fields affect black hole accretion?\"\n",
    "results = retriever.invoke(query)\n",
    "\n",
    "# Print retrieved results\n",
    "for doc in results:\n",
    "    print(f\"Content: {doc.page_content}\\nMetadata: {doc.metadata}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
