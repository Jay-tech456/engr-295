{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3b21937-4d73-4220-bcaf-809491a35c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in c:\\users\\jesh\\miniconda3\\lib\\site-packages (0.2.50)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: langsmith in c:\\users\\jesh\\miniconda3\\lib\\site-packages (0.1.143)\n",
      "Collecting langsmith\n",
      "  Downloading langsmith-0.3.18-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: langchain_anthropic in c:\\users\\jesh\\miniconda3\\lib\\site-packages (0.1.21)\n",
      "Collecting langchain_anthropic\n",
      "  Downloading langchain_anthropic-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.1 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from langgraph) (0.3.48)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.23-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.1.6-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.59-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from langsmith) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from langsmith) (3.10.6)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from langsmith) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from langsmith) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from langsmith) (2.32.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from langsmith) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith)\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting anthropic<1,>=0.49.0 (from langchain_anthropic)\n",
      "  Downloading anthropic-0.49.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (4.12.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.1)\n",
      "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
      "  Downloading ormsgpack-1.9.0-cp312-cp312-win_amd64.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.4/44.4 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langsmith) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langsmith) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from requests<3,>=2->langsmith) (2.2.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\jesh\\miniconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (2.1)\n",
      "Downloading langgraph-0.3.20-py3-none-any.whl (137 kB)\n",
      "   ---------------------------------------- 0.0/137.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 137.9/137.9 kB 8.5 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.3.18-py3-none-any.whl (351 kB)\n",
      "   ---------------------------------------- 0.0/351.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 351.9/351.9 kB 7.3 MB/s eta 0:00:00\n",
      "Downloading langchain_anthropic-0.3.10-py3-none-any.whl (25 kB)\n",
      "Downloading anthropic-0.49.0-py3-none-any.whl (243 kB)\n",
      "   ---------------------------------------- 0.0/243.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 243.4/243.4 kB 7.3 MB/s eta 0:00:00\n",
      "Downloading langgraph_checkpoint-2.0.23-py3-none-any.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.9/41.9 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading langgraph_prebuilt-0.1.6-py3-none-any.whl (25 kB)\n",
      "Downloading langgraph_sdk-0.1.59-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 47.0/47.0 kB ? eta 0:00:00\n",
      "Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "   ---------------------------------------- 0.0/495.6 kB ? eta -:--:--\n",
      "   ----------------------------- --------- 378.9/495.6 kB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 495.6/495.6 kB 10.3 MB/s eta 0:00:00\n",
      "Downloading ormsgpack-1.9.0-cp312-cp312-win_amd64.whl (125 kB)\n",
      "   ---------------------------------------- 0.0/125.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 125.3/125.3 kB ? eta 0:00:00\n",
      "Installing collected packages: zstandard, ormsgpack, langsmith, langgraph-sdk, anthropic, langgraph-checkpoint, langchain_anthropic, langgraph-prebuilt, langgraph\n",
      "  Attempting uninstall: zstandard\n",
      "    Found existing installation: zstandard 0.22.0\n",
      "    Uninstalling zstandard-0.22.0:\n",
      "      Successfully uninstalled zstandard-0.22.0\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.143\n",
      "    Uninstalling langsmith-0.1.143:\n",
      "      Successfully uninstalled langsmith-0.1.143\n",
      "  Attempting uninstall: langgraph-sdk\n",
      "    Found existing installation: langgraph-sdk 0.1.36\n",
      "    Uninstalling langgraph-sdk-0.1.36:\n",
      "      Successfully uninstalled langgraph-sdk-0.1.36\n",
      "  Attempting uninstall: anthropic\n",
      "    Found existing installation: anthropic 0.32.0\n",
      "    Uninstalling anthropic-0.32.0:\n",
      "      Successfully uninstalled anthropic-0.32.0\n",
      "  Attempting uninstall: langgraph-checkpoint\n",
      "    Found existing installation: langgraph-checkpoint 2.0.4\n",
      "    Uninstalling langgraph-checkpoint-2.0.4:\n",
      "      Successfully uninstalled langgraph-checkpoint-2.0.4\n",
      "  Attempting uninstall: langchain_anthropic\n",
      "    Found existing installation: langchain-anthropic 0.1.21\n",
      "    Uninstalling langchain-anthropic-0.1.21:\n",
      "      Successfully uninstalled langchain-anthropic-0.1.21\n",
      "  Attempting uninstall: langgraph\n",
      "    Found existing installation: langgraph 0.2.50\n",
      "    Uninstalling langgraph-0.2.50:\n",
      "      Successfully uninstalled langgraph-0.2.50\n",
      "Successfully installed anthropic-0.49.0 langchain_anthropic-0.3.10 langgraph-0.3.20 langgraph-checkpoint-2.0.23 langgraph-prebuilt-0.1.6 langgraph-sdk-0.1.59 langsmith-0.3.18 ormsgpack-1.9.0 zstandard-0.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Jesh\\miniconda3\\Lib\\site-packages\\~standard'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-community 0.3.0 requires langsmith<0.2.0,>=0.1.112, but you have langsmith 0.3.18 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langgraph langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd3f8b97-681e-4a9d-aa7b-eae92fa33cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain.chat_models import init_chat_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5119ce0b-0b35-473f-9097-67379afdd840",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "103b6b96-7517-451b-8512-61d9244d1a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1e24ff2ee70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# Initialize the Mistral model\n",
    "llm = init_chat_model(\"mistral-large-latest\", model_provider=\"mistralai\", api_key=\"ERbtRhtyGei4jY4AXn4QkrWSfGzlpLbP\")\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    \"\"\"\n",
    "    Function to handle the chatbot node.\n",
    "    It takes the current state and returns the AI response.\n",
    "    \"\"\"\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Add the chatbot node to the graph\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "675fd3e5-f97d-4e9b-9156-67026792ebc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1e24ff2ee70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a168d48-8d77-4953-bc01-0b61f600be8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1e24ff2ee70>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e5ffceb-00f7-4623-9ee5-0dc94a0c70ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0840f7b7-c1ce-4e11-8c90-fa84bb996756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4791f232-8bb3-456e-8f3b-8f51e5daf927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  Hello\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  who are you? \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I am a text-based AI model developed by the Mistral AI team. I'm here to help answer your questions, provide explanations, or just chat on a wide range of topics. I don't have personal experiences or emotions, but I'm designed to understand and generate human-like text based on the data I've been trained on (up until 2021). How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  could you answer questions about sir issac newton \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: Absolutely, I'd be happy to help with questions about Sir Isaac Newton. Here are some key points about him:\n",
      "\n",
      "### Basic Information\n",
      "- **Full Name**: Isaac Newton\n",
      "- **Birthdate**: January 4, 1643\n",
      "- **Death**: March 31, 1727\n",
      "- **Nationality**: English\n",
      "- **Occupation**: Mathematician, physicist, astronomer, theologian, and author\n",
      "\n",
      "### Major Contributions\n",
      "1. **Laws of Motion**: Newton formulated the three laws of motion, which are fundamental to classical mechanics.\n",
      "   - **First Law**: An object at rest stays at rest, and an object in motion stays in motion, unless acted upon by an unbalanced force.\n",
      "   - **Second Law**: The force acting on an object is equal to its mass times its acceleration (F = ma).\n",
      "   - **Third Law**: For every action, there is an equal and opposite reaction.\n",
      "\n",
      "2. **Universal Law of Gravitation**: He described the universal law of gravitation, which states that any two objects in the universe attract each other with a force that is directly proportional to the product of their masses and inversely proportional to the square of the distance between their centers.\n",
      "\n",
      "3. **Philosophiæ Naturalis Principia Mathematica (Mathematical Principles of Natural Philosophy)**: Published in 1687, this work is considered one of the most influential books in the history of science.\n",
      "\n",
      "4. **Optics**: Newton made significant contributions to optics, including his work on the nature of light and color, and the invention of the reflecting telescope.\n",
      "\n",
      "5. **Calculus**: Newton and Gottfried Wilhelm Leibniz independently developed calculus, although there was a dispute over priority.\n",
      "\n",
      "### Personal Life\n",
      "- **Education**: Newton attended Trinity College, Cambridge.\n",
      "- **Career**: He held positions such as the Lucasian Professor of Mathematics at Cambridge University and Master of the Mint.\n",
      "- **Interests**: Apart from his scientific work, Newton had a keen interest in alchemy and theology.\n",
      "\n",
      "### Legacy\n",
      "- **Scientific Revolution**: Newton is often considered one of the key figures of the Scientific Revolution.\n",
      "- **Influence**: His work laid the foundation for classical mechanics and has influenced generations of scientists.\n",
      "- **Honors**: He was knighted by Queen Anne in 1705 and became Sir Isaac Newton.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb225a62-1778-4063-9b3d-7c0a87df5f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf7c125-f2cb-4af6-b96b-f57e2ed40d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version  2 : Invoking a Tool with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad0170f-d729-4ef1-9194-ef6e846c40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Create a basic math tool\n",
    "@tool(\"basic_math\")\n",
    "def basic_math_tool(operation: str, a: float, b: float) -> Dict:\n",
    "    \"\"\"\n",
    "    A simple math tool that performs addition, subtraction, multiplication, and division.\n",
    "\n",
    "    Args:\n",
    "    - operation (str): The math operation to perform (add, subtract, multiply, divide).\n",
    "    - a (float): First number.\n",
    "    - b (float): Second number.\n",
    "\n",
    "    Returns:\n",
    "    - Dict: The result of the operation.\n",
    "    \"\"\"\n",
    "    if operation == \"add\":\n",
    "        return {\"result\": a + b}\n",
    "    elif operation == \"subtract\":\n",
    "        return {\"result\": a - b}\n",
    "    elif operation == \"multiply\":\n",
    "        return {\"result\": a * b}\n",
    "    elif operation == \"divide\":\n",
    "        if b == 0:\n",
    "            return {\"error\": \"Cannot divide by zero\"}\n",
    "        return {\"result\": a / b}\n",
    "    else:\n",
    "        return {\"error\": \"Invalid operation\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d4cd60-7f0e-46ab-95a9-beb774cce942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877bcc2d-4ed1-4f8c-9e71-dcce53d17a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17ffcc91-a152-49b6-9c77-114d3a842ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5fe879-2d81-46b9-a8b5-45ade2f4724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_node(state: State):\n",
    "    \"\"\"\n",
    "    Node that invokes the math tool.\n",
    "    \"\"\"\n",
    "    message = state[\"messages\"][-1][\"content\"].lower()  # Extract the message content\n",
    "\n",
    "    # Example of tool invocation based on a trigger phrase\n",
    "    if \"calculate\" in message:\n",
    "        try:\n",
    "            _, operation, a, b = message.split()  # Extract parameters\n",
    "            a, b = float(a), float(b)  # Convert to floats\n",
    "            result = basic_math_tool(operation, a, b)\n",
    "            \n",
    "            # Format the response\n",
    "            response = f\"Result: {result['result']}\" if \"result\" in result else result['error']\n",
    "\n",
    "        except ValueError:\n",
    "            response = \"Invalid input. Please use the format: 'calculate add 10 5'.\"\n",
    "\n",
    "    else:\n",
    "        response = \"I can only calculate math operations.\"\n",
    "\n",
    "    # Return with the correct message format\n",
    "    return {\"messages\": [{\"role\": \"ai\", \"content\": response}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37cc03fb-4325-42b2-a9cf-9b597b976ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1cb08265400>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the tool node to the graph\n",
    "graph_builder.add_node(\"math_tool\", tool_node)\n",
    "\n",
    "def chatbot(state: ChatState):\n",
    "    \"\"\"\n",
    "    LLM node that handles the chatbot interactions.\n",
    "    \"\"\"\n",
    "    # Add the 'role' key to the LLM invocation message\n",
    "    llm_messages = [{\"role\": msg.get(\"role\", \"user\"), \"content\": msg[\"content\"]} for msg in state[\"messages\"]]\n",
    "\n",
    "    # Invoke the LLM with properly formatted messages\n",
    "    response = llm.invoke(llm_messages)\n",
    "\n",
    "    return {\"messages\": [{\"role\": \"ai\", \"content\": response}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff959db-bc58-4dcc-b16f-841680d37f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add LLM node\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "graph_builder.set_entry_point(\"math_tool\")\n",
    "graph_builder.add_edge(\"math_tool\", \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78e5c59e-554b-47bf-8f32-5965dd40d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bb54401-e293-4520-9f9b-f025079d2c93",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'HumanMessage' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalculate add 10 5\u001b[39m\u001b[38;5;124m\"\u001b[39m}]}  \u001b[38;5;66;03m# Correct format\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Run the graph\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Print the response\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAI Response:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2683\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2682\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2683\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2684\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2687\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2688\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2689\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2691\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2692\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2693\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2331\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2325\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   2326\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   2327\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   2328\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   2329\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   2330\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 2331\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2333\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2334\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2335\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2336\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   2337\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   2338\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2339\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\langgraph\\pregel\\runner.py:146\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    144\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\langgraph\\utils\\runnable.py:606\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    602\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    603\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    604\u001b[0m )\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 606\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\langgraph\\utils\\runnable.py:371\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 371\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m, in \u001b[0;36mtool_node\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtool_node\u001b[39m(state: State):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Node that invokes the math tool.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Example of tool invocation based on a trigger phrase\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalculate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m message:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'HumanMessage' object is not subscriptable",
      "\u001b[0mDuring task with name 'math_tool' and id '5ebee54c-8414-6b4b-348d-0b2d1d2480c5'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Updated state with the correct message format\n",
    "state = {\"messages\": [{\"role\": \"user\", \"content\": \"calculate add 10 5\"}]}  # Correct format\n",
    "\n",
    "\n",
    "# Run the graph\n",
    "output = graph.invoke(state)\n",
    "\n",
    "# Print the response\n",
    "print(\"AI Response:\", output[\"messages\"][-1][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c11d4f1-4969-4b00-819e-f38c1c1e641c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ff038b-eaf6-42fa-85a1-91475d12f56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21ff0770-3239-4c95-86e7-9c795e3595db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2275c6ffbc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3d9a454-ee1d-4bf3-ac72-eaee0eadcd6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m llm \u001b[38;5;241m=\u001b[39m init_chat_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistral-large-latest\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_provider\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai\u001b[39m\u001b[38;5;124m\"\u001b[39m, api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERbtRhtyGei4jY4AXn4QkrWSfGzlpLbP\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Modification: tell the LLM which tools it can call\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m llm_with_tools \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mbind_tools(\u001b[43mtools\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tools' is not defined"
     ]
    }
   ],
   "source": [
    "llm = init_chat_model(\"mistral-large-latest\", model_provider=\"mistralai\", api_key=\"ERbtRhtyGei4jY4AXn4QkrWSfGzlpLbP\")\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72200a79-0678-49db-8ab1-d5f49ba8c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0430b1-850e-4cd9-9ef9-36c494dd4044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135b230-93a0-46b3-9335-cc595200f42d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
